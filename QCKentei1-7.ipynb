{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diseño Experimental\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-01 Diseño Experimental\n",
    "\n",
    "### 1. Diseño Experimental\n",
    "\n",
    "En el diseño experimental, mediante el análisis de varianza, se puede obtener la siguiente información.\n",
    "* Prueba de efectos de factores\n",
    "* Estimación de efectos de factores\n",
    "* Estimación de errores\n",
    "\n",
    "La guía para el agrupamiento es que el valor de F0 sea inferior a 2, o que no sea significativo con un nivel de significancia de aproximadamente el 20%.\n",
    "\n",
    "Estimación de la media poblacional bajo condiciones óptimas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Experimento de diseño factorial\n",
    "\n",
    "Se seleccionan tres factores que afectan a los valores de las características, tomando el factor A con $ l $ niveles, el factor B con $ m $ niveles y el factor C con $ n $ niveles, y se realiza un experimento en todas las combinaciones posibles de niveles de los tres factores. Los experimentos se realizan en un orden aleatorio de todas las combinaciones. Este tipo de experimento se llama experimento de diseño trifactorial.\n",
    "\n",
    "En un experimento de diseño trifactorial, se pueden analizar las interacciones de dos factores como AxB, AxC y BxC, y además, si se repiten las pruebas para cada combinación de niveles, también se puede analizar la interacción de tres factores AxBxC. Además, los experimentos que manejan más de tres factores se llaman experimentos de diseño factorial múltiple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-02 Experimento de diseño ortogonal\n",
    "\n",
    "### 1.Experimento de diseño de tablas ortogonales\n",
    "\n",
    "Se puede realizar la prueba de los efectos principales y de las interacciones que se desean analizar con un número reducido de experimentos.\n",
    "\n",
    "Es necesario clasificar de antemano las interacciones en aquellas que se deben considerar y las que se deben ignorar.\n",
    "\n",
    "* Tabla ortogonal de dos niveles\n",
    "* Tabla ortogonal de tres niveles\n",
    "\n",
    "\n",
    "### 2. Experimento de diseño de tablas ortogonales de dos niveles\n",
    "\n",
    "#### (1) Experimento de diseño de tabla ortogonal de dos niveles\n",
    "\n",
    "$ L_8(2^7) $ : Símbolo de la matriz\n",
    "* 8: Número de filas (número de experimentos)\n",
    "* 2: Dos niveles\n",
    "* 7: Número de columnas (número máximo de factores que incluyen el error\n",
    "\n",
    "#### (2) Tratamiento de interacciones\n",
    "\n",
    "* Solo se considera la interacción de dos factores.\n",
    "* La presencia o ausencia de la interacción debe determinarse previamente.\n",
    "* La interacción de dos factores aparece en una sola columna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Asignación\n",
    "* Uso de la diagrama de puntos y líneas\n",
    "* Experimento de arreglo ortogonal L16 (muestreo aleatorio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "  os.chdir('../Python/QCKentei')\n",
    "except:\n",
    "  pass\n",
    "\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from scipy.stats import f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de arreglo ortogonal L16 (muestreo aleatorio):\n",
      "    A  B  C  D  F  G\n",
      "0   3  1  2  1  2  2\n",
      "1   3  2  1  1  2  2\n",
      "2   2  1  1  1  2  2\n",
      "3   2  2  2  2  2  2\n",
      "4   1  2  2  1  2  1\n",
      "5   2  1  2  1  2  2\n",
      "6   1  2  2  2  1  2\n",
      "7   1  1  2  2  2  1\n",
      "8   1  1  1  1  1  1\n",
      "9   2  2  2  1  1  1\n",
      "10  2  2  1  2  1  2\n",
      "11  1  1  2  1  2  1\n",
      "12  1  1  2  2  1  1\n",
      "13  2  2  1  1  1  1\n",
      "14  2  1  2  1  2  1\n",
      "15  3  1  1  1  2  1\n"
     ]
    }
   ],
   "source": [
    "from pyDOE2 import fullfact\n",
    "import pandas as pd\n",
    "\n",
    "# Especificar los niveles de cada factor\n",
    "levels = [3, 2, 2, 2, 2, 2]  # A: 3 niveles, B～G: 2 niveles\n",
    "\n",
    "# Generar todas las combinaciones de factores utilizando fullfact\n",
    "design = fullfact(levels)\n",
    "\n",
    "# Covertir los niveles a enteros (0, 1, 2 -> 1, 2, 3)\n",
    "design = design.astype(int) + 1\n",
    "\n",
    "# Muestreo aleatorio para obtener el número necesario de filas (hacerlo L16)\n",
    "design = pd.DataFrame(design, columns=['A', 'B', 'C', 'D', 'F', 'G']).sample(n=16, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Tabla de arreglo ortogonal L16 (muestreo aleatorio):\")\n",
    "print(design)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1\n",
    "\n",
    "Q社では機械部品の強度を高めるため強度に影響を及ぼすと考えられる母数因子A、B、C、D、F、Gの六つを取り上げ、いずれも2水準で実験を行った。交互作用としては、AxB、AxC、DxF、CxGの4つが技術的に考えられる。L16直交配列表実験とし、16回の実験はランダムな順序で行った。主効果の割り付けと得られたデータを表7.2に示す。なお、値は大きい方が望ましい。以下の設問に答えよ。\n",
    "1. データの構造式を示せ\n",
    "4. 分散分析表を作成せよ\n",
    "5. プーリング後の分散分析表を作成せよ\n",
    "6. 分散分析後のデータ構造式を示し、最適条件を求めよ\n",
    "7. 最適条件における母平均を点推定し、信頼率95%で区間推定せよ\n",
    "\n",
    "\n",
    "La empresa Q realizó experimentos para aumentar la resistencia de piezas mecánicas, tomando en cuenta seis factores principales que se consideran influyentes en la resistencia: A, B, C, D, F y G, todos ellos con 2 niveles. Como interacciones, se consideran técnicamente AxB, AxC, DxF y CxG. Se utilizó un experimento de arreglo ortogonal L16, y los 16 experimentores se realizaron en un orden aleatorio. La asignación de los efectos principales y los datos obtenidos se muestran en la tabla 7.2. Cabe señalar que es preferible que los valores sean mayores. Responda las siguientes preguntas.\n",
    "1. Mostrar la estructura de los datos.\n",
    "4. Elaborar la tabla de análisis de varianza\n",
    "5. Elaborar la tabla de análisis de varianza después de la agrupación (pooling)\n",
    "6. Mostrar la estructura de los datos después del análisis de varianza y determinar las condiciones óptimas\n",
    "7. Realizar la estimación puntual de la media poblacional bajo las condiciones óptimas y realizar una estimación de intervalo con un nivel de confianza del 95%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gspread \n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "# 認証情報の設定\n",
    "SERVICE_ACCOUNT_FILE = \"my-project-vscode-452201-249bdb033f8c.json\"  # JSONファイルのパス\n",
    "SCOPES = [\"https://www.googleapis.com/auth/spreadsheets\"]\n",
    "\n",
    "credentials = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "client = gspread.authorize(credentials)\n",
    "\n",
    "# スプレッドシートを開く（URLまたはスプレッドシートIDを使用）\n",
    "SPREADSHEET_ID = \"1RkO0VL4WR6cbPBfBEjz693Lo4SdUAoSvRHV491ggXTo\"\n",
    "\n",
    "sheet = client.open_by_key(SPREADSHEET_ID).worksheet(\"Sheet13\") # 最初のシートを取得\n",
    "\n",
    "# データを取得\n",
    "list_of_lists = sheet.get_all_values()\n",
    "df = pd.DataFrame.from_records(list_of_lists)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(index=0)\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "df = df.apply(pd.to_numeric)\n",
    "\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 7.2 Asignacíon y datos\n",
      "0           A  B  F   G  C    D    y\n",
      "1           1  1  1   1  1    1   52\n",
      "2           1  1  1   1  2    2  103\n",
      "3           1  1  2   2  1    1   50\n",
      "4           1  1  2   2  2    2  166\n",
      "5           1  2  1   1  1    2  124\n",
      "6           1  2  1   1  2    1   87\n",
      "7           1  2  2   2  1    2  187\n",
      "8           1  2  2   2  2    1   41\n",
      "9           2  1  1   2  1    2  185\n",
      "10          2  1  1   2  2    1  125\n",
      "11          2  1  2   1  1    2  223\n",
      "12          2  1  2   1  2    1  131\n",
      "13          2  2  1   2  1    1  134\n",
      "14          2  2  1   2  2    2   77\n",
      "15          2  2  2   1  1    1   65\n",
      "16          2  2  2   1  2    2  154\n",
      "Componente  a  b  c  ac  d  abd    -\n"
     ]
    }
   ],
   "source": [
    "data = data.T\n",
    "data['Componente'] = ['a', 'b', 'c', 'ac', 'd', 'abd', '-']\n",
    "data = data.T\n",
    "\n",
    "print('Tabla 7.2 Asignacíon y datos')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Estructura de los datos\n",
    "\n",
    "$ x = \\mu + a + b + c + d + f + g + (ab) + (ac) + (df) + (dg) + \\epsilon  $\n",
    "\n",
    "Restricciones:\n",
    "\n",
    "$ \\sum a = \\sum b = \\sum c = \\sum d = \\sum f = \\sum g = 0 $\n",
    "\n",
    "$ \\sum (ab) = \\sum (df) = \\sum (dg) = 0 $\n",
    "\n",
    "$ \\sum (ab) = (ab)_{11} + (ab)_{12} = (ab)_{21} + (ab)_{22} = (ab)_{11} + (ab)_{21} = (ab)_{12} + (ab)_{22} = 0 $\n",
    "\n",
    "$ \\epsilon \\sim N(0, \\sigma^2) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tabla 7.5 Tabla de análisis de varianza:\n",
      "           df    sum_sq   mean_sq          F    PR(>F)\n",
      "A         1.0   5041.00   5041.00   6.312692  0.053663\n",
      "B         1.0   1722.25   1722.25   2.156722  0.201883\n",
      "C         1.0   1156.00   1156.00   1.447624  0.282766\n",
      "D         1.0  17822.25  17822.25  22.318264  0.005223\n",
      "F         1.0   1056.25   1056.25   1.322710  0.302125\n",
      "G         1.0     42.25     42.25   0.052908  0.827192\n",
      "A:B       1.0   5700.25   5700.25   7.138251  0.044256\n",
      "A:C       1.0    676.00    676.00   0.846534  0.399749\n",
      "D:F       1.0   7744.00   7744.00   9.697577  0.026428\n",
      "D:G       1.0      1.00      1.00   0.001252  0.973140\n",
      "Residual  5.0   3992.75    798.55        NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# 4. Tabla de análisis de varianza\n",
    "\n",
    "# Definición del modelo de regresón\n",
    "formula = 'y ~ A + B + C + D + F + G + A:B + A:C + D:F + D:G'\n",
    "\n",
    "# Realización del análisis de regresión\n",
    "model = ols(formula, data=df).fit()\n",
    "\n",
    "# Elaboración de la tabla de análisis de varianza\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"\\nTabla 7.5 Tabla de análisis de varianza:\")\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool(anova_table, pool_factors, pool_):\n",
    "  # Calcular el error agrupado (pooling)\n",
    "  pooled_error_ss = anova_table.loc[pool_factors, 'sum_sq'].sum()  # Calucar el error agrupado (pooling)\n",
    "  pooled_error_df = anova_table.loc[pool_factors, 'df'].sum()      # Calucar el grados de libertad agrupado (pooling)\n",
    "\n",
    "  # Tabla de análisis de varianza de los factores\n",
    "  anova_table = anova_table.drop(index=pool_factors)\n",
    "\n",
    "  # Actualizar el término de error\n",
    "  anova_table.loc[pool_] = [\n",
    "      anova_table.loc[pool_, 'sum_sq'] + pooled_error_ss,  # Nueva suma de cuadrados del error\n",
    "      anova_table.loc[pool_, 'df'] + pooled_error_df,      # Nuevos grados de libertad\n",
    "      None,  # Mean Square\n",
    "      None   # F-statistic\n",
    "  ]\n",
    "\n",
    "  # Calcular la media de los cuadrados\n",
    "  anova_table['mean_sq'] = anova_table['sum_sq'] / anova_table['df']\n",
    "\n",
    "  # Calcular el valor F\n",
    "  anova_table['F'] = anova_table['mean_sq'] / anova_table.loc['Residual', 'mean_sq']\n",
    "\n",
    "  # Calcular el valor p\n",
    "  anova_table['PR(>F)'] = f.sf(anova_table['F'], anova_table['df'], anova_table.loc['Residual', 'df'])\n",
    "\n",
    "  return anova_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 7.6 Tabla de análisis de varianza (después de pooling):\n",
      "            sum_sq   df          F    PR(>F)   mean_sq\n",
      "A          5041.00  1.0   7.731595  0.021381   5041.00\n",
      "B          1722.25  1.0   2.641488  0.138551   1722.25\n",
      "D         17822.25  1.0  27.334739  0.000543  17822.25\n",
      "F          1056.25  1.0   1.620015  0.234984   1056.25\n",
      "A:B        5700.25  1.0   8.742715  0.016042   5700.25\n",
      "D:F        7744.00  1.0  11.877301  0.007317   7744.00\n",
      "Residual   5868.00  9.0   1.000000  0.500000    652.00\n"
     ]
    }
   ],
   "source": [
    "# 5. Elaborar la tabla de análisis de varianza después de la agrupación (pooling)\n",
    "\n",
    "# Obtener la tabla de análisis de varianza\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table = pool(anova_table,['C', 'G', 'A:C', 'D:G'], 'Residual')\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Tabla 7.6 Tabla de análisis de varianza (después de pooling):\")\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Estructura de los datos después del análisis de varianza\n",
    "\n",
    "$ x = \\mu + a + b + d + f + (ab) + (df) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimación de la media poblacional en las condicones óptimas: 229.5\n"
     ]
    }
   ],
   "source": [
    "# 7. Estimación puntual del media poblacional en las condiciones óptimas\n",
    "\n",
    "means=0\n",
    "for factor in [ ['A','B'], ['D','F']]:\n",
    "    means += df.groupby(factor)['y'].mean().max()\n",
    "\n",
    "mean_x = means - df['y'].mean()\n",
    "\n",
    "print(f\"Estimación de la media poblacional en las condicones óptimas: {mean_x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervalo de confianza del 95%: (191.3, 267.7)\n"
     ]
    }
   ],
   "source": [
    "# 7. Estimaci[on de intervalo con un nivel de confianza del 95%]\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Número efectivo de repeticiones\n",
    "N = len(df)\n",
    "s = 1\n",
    "\n",
    "for i in ['A','B','D','F','A:B','D:F']:\n",
    "  s += anova_table.loc[i,'df']\n",
    "ne = s/N\n",
    "\n",
    "# Varianza del error\n",
    "Ve = anova_table.loc['Residual','mean_sq']\n",
    "df2= anova_table.loc['Residual','df']\n",
    "\n",
    "p = 0.05\n",
    "t_value = stats.t.ppf(1 - p/2, df=df2)\n",
    "\n",
    "S = (ne*Ve)**0.5\n",
    "\n",
    "UL = mean_x + t_value*S\n",
    "LL = mean_x - t_value*S\n",
    "\n",
    "print(f\"Intervalo de confianza del 95%: ({LL:.1f}, {UL:.1f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Experimento con arreglo ortogonal de 3 niveles\n",
    "\n",
    "#### (1) Experimento con arreglo ortogonal de 3 niveles\n",
    "\n",
    "En el experimento con arreglo ortogonal de 3 niveles, se manejan factores de 3 niveles. El concepto y el método de análisis son casi los mismos que en el caso de 2 niveles, pero hay una diferencia importante: el grado de libertad del efecto principal de un factor de 3 niveles es 2, por lo que el grado de libertad de una sola columna es 2, y el grado de libertad de una interacción es 2x2=4. Debido a esto, la interacción aparece en dos columnas.\n",
    "\n",
    "$ L_{27} (3^{13}) :$\n",
    "\n",
    "27: Número de filas como número de experimentos\n",
    "\n",
    "3: Sistema de 3 niveles\n",
    "\n",
    "13: Número de columnas\n",
    "\n",
    "### (2) Manejo y asignación de las interacciones\n",
    "\n",
    "Cuando los simbolos de los componentes de las columnas asignadas a los factores X y Z son p y q, respectivamente, la interacción $ X \\times Y $ aparece en dos columnas cuyos símbolos de componentes son $ p \\times q $ y $ p \\times q^2 $. Aquí, se asume que $ a^2 = b^2 = c^2 ... = 1 $. Si no se encuentra una columna correspondiente mediante este procedimiento, se considera el cuadrado de los componentes obtenidos, es decir $ (pq)^2 $ o $ (pq^2)^2 $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2\n",
    "\n",
    "Q社では、水中の残留成分の低減に取り組むことになった。残留成分に影響を与えると考えられるA、B、C、D、Fの五つの母数因子（各3水準）を取り上げ、$ L_{27} $ 直交配列表により実験した。\n",
    "\n",
    "交互作用は、技術的に見てAxB、AxD、AxFの３つが考えられる。27回の実験はランダムな順序で行った。主効果の割り付けと得られたデータ表を表7.9に示す。値は小さい方が望ましい。以下の設問に答えよ。\n",
    "\n",
    "2. 分散分析表を作成し、プーリングについて検討せよ\n",
    "\n",
    "En la empresa Q, se ha decidido trabajar en la reducción de los componentes residuales en el agua. Se seleccionaron cinco factores poblacionales (A, B, C, D y F), cada uno con 3 niveles, que se consideran influyentes en los componentes residuales, y se realizó el experimento utilizando un arreglo ortogonal L27.\n",
    "\n",
    "Las interacciones que se consideran posibles desde el punto de vista técnico son tres: AxB, AxD y AxF. Los 27 experimentos se realizaron en un orden aleatorio. La asignación de los efectos principales y tabla de datos obtenidos se muestran en la Tabla 7.9. Se desea que los valores sean lo más pequeños posible. Responda a las siguientes preguntas.\n",
    "\n",
    "2. Elabora la tabla de análisis de varianza y examina la posibilidad de pooling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los datos (como lista)\n",
    "sheet = client.open_by_key(SPREADSHEET_ID).worksheet(\"Sheet15\") # 最初のシートを取得\n",
    "\n",
    "# データを取得\n",
    "list_of_lists = sheet.get_all_values()\n",
    "\n",
    "df = pd.DataFrame.from_records(list_of_lists)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(index=0)\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "df['x'] = df['x'].apply(pd.to_numeric)\n",
    "\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 7.9 Asignacíon y datos\n",
      "0           A  B     F   G  D     x\n",
      "1           1  1     1   1  1  0.63\n",
      "2           1  2     2   2  1  0.64\n",
      "3           1  3     3   3  1  0.27\n",
      "4           1  1     3   2  2  0.52\n",
      "5           1  2     1   3  2  0.48\n",
      "6           1  3     2   1  2  0.61\n",
      "7           1  1     2   3  3  0.75\n",
      "8           1  2     3   1  3  0.42\n",
      "9           1  3     1   2  3  0.46\n",
      "10          2  1     1   1  1  0.59\n",
      "11          2  2     2   2  1  0.68\n",
      "12          2  3     3   3  1  0.49\n",
      "13          2  1     3   2  2  0.46\n",
      "14          2  2     1   3  2  0.66\n",
      "15          2  3     2   1  2   0.8\n",
      "16          2  1     2   3  3  0.86\n",
      "17          2  2     3   1  3  0.66\n",
      "18          2  3     1   2  3  0.97\n",
      "19          3  1     1   1  1  0.62\n",
      "20          3  2     2   2  1  0.64\n",
      "21          3  3     3   3  1  0.44\n",
      "22          3  1     3   2  2  0.39\n",
      "23          3  2     1   3  2  0.49\n",
      "24          3  3     2   1  2  0.82\n",
      "25          3  1     2   3  3  0.89\n",
      "26          3  2     3   1  3  0.29\n",
      "27          3  3     1   2  3  0.45\n",
      "Componente  a  c  bc^2  bc  d     -\n"
     ]
    }
   ],
   "source": [
    "data = data.T\n",
    "data['Componente'] = ['a', 'c','bc^2', 'bc', 'd', '-']\n",
    "data = data.T\n",
    "\n",
    "print('Tabla 7.9 Asignacíon y datos')\n",
    "print(data)\n",
    "\n",
    "data.to_excel('Data_1/data15.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           df    sum_sq   mean_sq          F    PR(>F)\n",
      "A         2.0  0.122007  0.061004  10.142241  0.027131\n",
      "B         2.0  0.031296  0.015648   2.601601  0.188904\n",
      "G         2.0  0.002941  0.001470   0.244458  0.794030\n",
      "D         2.0  0.032807  0.016404   2.727217  0.178998\n",
      "F         2.0  0.420230  0.210115  34.932882  0.002932\n",
      "A:B       4.0  0.083370  0.020843   3.465209  0.128001\n",
      "A:D       4.0  0.067926  0.016981   2.823276  0.169448\n",
      "A:F       4.0  0.045170  0.011293   1.877463  0.278382\n",
      "Residual  4.0  0.024059  0.006015        NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Convertir los factores en tipo categórico\n",
    "factors = df.columns.tolist()\n",
    "for factor in factors[:-1]:\n",
    "    df[factor] = df[factor].astype('category')\n",
    "\n",
    "# Crear un modelo de análisis de\n",
    "model = ols('x ~ A + B + G + D + F + A:B + A:D + A:F', data=df).fit()\n",
    "\n",
    "# Elaboración de la tabla de análisis de varianza\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de análisis de varianza (despues de pooling):\n",
      "            sum_sq    df          F    PR(>F)   mean_sq\n",
      "A         0.122007   2.0   8.452735  0.007092  0.061004\n",
      "B         0.031296   2.0   2.168223  0.165117  0.015648\n",
      "D         0.032807   2.0   2.272914  0.153570  0.016404\n",
      "F         0.420230   2.0  29.113723  0.000068  0.210115\n",
      "A:B       0.083370   4.0   2.887971  0.079145  0.020843\n",
      "A:D       0.067926   4.0   2.352971  0.124230  0.016981\n",
      "Residual  0.072170  10.0   1.000000  0.500000  0.007217\n"
     ]
    }
   ],
   "source": [
    "# Obtener la tabla de análisis de varianza\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table = pool(anova_table,['G', 'A:F'], 'Residual')\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Tabla de análisis de varianza (despues de pooling):\")\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-03 Método de múltiples niveles y Método cuasi-nivelado\n",
    "\n",
    "#### 1. Método de múltiples niveles y Método cuasi-nivelado\n",
    "\n",
    "Al realizar experimentos utilizando tablas de diseño ortogonal, puede haber casos en los que sea difícil o inconveniente unificar todos los factores a dos o tres niveles. En tales casos, también es posible realizar experimentos utilizando factores con nun número de niveles diferente al de la mayoría de los otros factores.\n",
    "\n",
    "#### 2. Método de múltiples niveles utilizando una tabla ortogonal de dos niveles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A  B  C  D  E  F\n",
      "0   1  1  1  1  1  1\n",
      "1   1  1  2  2  2  2\n",
      "2   3  1  1  1  2  2\n",
      "3   3  1  2  2  1  1\n",
      "4   4  1  1  2  1  2\n",
      "5   4  1  2  1  2  1\n",
      "6   2  1  1  2  2  1\n",
      "7   2  1  2  1  1  2\n",
      "8   3  2  1  2  2  1\n",
      "9   3  2  2  1  1  2\n",
      "10  1  2  1  2  1  2\n",
      "11  1  2  2  1  2  1\n",
      "12  2  2  1  1  1  1\n",
      "13  2  2  2  2  2  2\n",
      "14  4  2  1  1  1  1\n",
      "15  4  2  2  2  2  2\n"
     ]
    }
   ],
   "source": [
    "# L16 ortogonal（2^15: 15 columns × 16 filas）\n",
    "L16 = [\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "    [1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2],\n",
    "    [1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1],\n",
    "    [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1],\n",
    "    [1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2],\n",
    "    [1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1],\n",
    "    [1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2],\n",
    "    [2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2],\n",
    "    [2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1],\n",
    "    [2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2],\n",
    "    [2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1],\n",
    "    [2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1],\n",
    "    [2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2],\n",
    "    [2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1],\n",
    "    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2]\n",
    "]\n",
    "\n",
    "# DataFrame de la tabla L16\n",
    "df = pd.DataFrame(L16, columns=['B', 'L2', 'L3', 'L1', 'C', 'D', 'E', 'F', 'L9', 'L10', 'L11', 'L12', 'L13', 'L14', 'L15'])\n",
    "\n",
    "# Crear el factor A con 4 niveles (generado a partir de la combinación de L1, L2 y L3)\n",
    "def convert_to_4_levels(row):\n",
    "    return (row['L1'] - 1)*2  + (row['L2'] - 1) + 1\n",
    "\n",
    "df['A'] = df[['L1', 'L2', 'L3']].apply(convert_to_4_levels, axis=1)\n",
    "\n",
    "# Eliminar L1, L2, L3（ya que se han integrado en A）\n",
    "df = df.drop(columns=['L1', 'L2', 'L3', 'L9', 'L10', 'L11', 'L12', 'L13', 'L14', 'L15'])\n",
    "\n",
    "# Ordenar las columnas\n",
    "df = df[['A', 'B', 'C', 'D', 'E', 'F']]\n",
    "\n",
    "# Ordenar las columnas\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Método cuasi-nivelado utilizando una tabla ortogonal de tres niveles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Método cuasi-nivelado utilizando una tabla ortogonal de dos niveles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A  B  C  D  F  G\n",
      "0   1  1  1  1  1  1\n",
      "1   2  1  1  1  1  2\n",
      "2   3  1  1  2  2  1\n",
      "3   2  1  1  2  2  2\n",
      "4   1  1  2  1  2  1\n",
      "5   2  1  2  1  2  2\n",
      "6   3  1  2  2  1  1\n",
      "7   2  1  2  2  1  2\n",
      "8   1  2  1  1  2  1\n",
      "9   2  2  1  1  2  2\n",
      "10  3  2  1  2  1  1\n",
      "11  2  2  1  2  1  2\n",
      "12  1  2  2  1  1  1\n",
      "13  2  2  2  1  1  2\n",
      "14  3  2  2  2  2  1\n",
      "15  2  2  2  2  2  2\n"
     ]
    }
   ],
   "source": [
    "# L16(2^15) Tablas de diseño ortogonal\n",
    "# (definición de los más representativos)\n",
    "L16 = np.array([\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "    [1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2],\n",
    "    [1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1],\n",
    "    [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1],\n",
    "    [1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2],\n",
    "    [1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2],\n",
    "    [1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1],\n",
    "    [2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1],\n",
    "    [2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2],\n",
    "    [2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1],\n",
    "    [2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2],\n",
    "    [2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1],\n",
    "    [2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2],\n",
    "    [2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1],\n",
    "    [2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2]\n",
    "])\n",
    "\n",
    "# Asignación de A (tres niveles): duplicar A2 para expresarlo\n",
    "# en una tabla ortogonal de dos niveles\n",
    "\n",
    "A = np.tile([1, 2, 3, 2], 4)\n",
    "B, C, D, F, G = L16[:, 0], L16[:, 1], L16[:, 2], L16[:, 3], L16[:, 4]\n",
    "\n",
    "# Elaborar una tabla de planificación experimental\n",
    "df = pd.DataFrame({\n",
    "    'A': A,\n",
    "    'B': B,\n",
    "    'C': C,\n",
    "    'D': D,\n",
    "    'F': F,\n",
    "    'G': G\n",
    "})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3\n",
    "Q社では、塗料の付着性に影響するA、B、C、D、F、Gの六つの母数因子を取り上げ実験を行った。Aは３水準とし、他は２水準とした。交互作用はAxB、AxC、BxCの三つが技術的に考えられるため、L16直交配列表実験とし、１６回の実験はランダムな順序で行い、割り付けと得られたデータ表を7.14に示す。値は大きい方が望ましい。\n",
    "\n",
    "2. 分散分析表を完成させよ。\n",
    "\n",
    "En la empresa Q, se realizó un experimento considerando seis factores principales que afectan la adherencia de la pintura: A, B, C, D, F y G. El factor A se estableció en tres niveles, mientras que los demás dos niveles. Dado que técnicamente se consideran posibles tres interacciones: AxB, AxC y BxC, se llevó a cabo un experimento utilizando la tabla ortogonal L16. Los ensayos se realizaron en un orden aleatorio. La asignación y los datos obtenidos se muestran en la Tabla 7.14. Un valor es más deseable.\n",
    "\n",
    "2. Calcule cada suma de cuadrados y compute la tabla de análisis de varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 7.14 Asignacíon y datos\n",
      "0       A    B    E     D     F     G   y\n",
      "1       1    1    1     1     1     1  29\n",
      "2       1    1    2     2     2     2  17\n",
      "3       2    1    1     1     2     2  22\n",
      "4       2    1    2     2     1     1  10\n",
      "5       3    1    1     2     1     2  29\n",
      "6       3    1    2     1     2     1  35\n",
      "7       2    1    1     2     2     1  26\n",
      "8       2    1    2     1     1     2  28\n",
      "9       1    2    1     2     2     2  13\n",
      "10      1    2    2     1     1     1  35\n",
      "11      2    2    1     2     1     1  46\n",
      "12      2    2    2     1     2     2  60\n",
      "13      3    2    1     1     2     1  21\n",
      "14      3    2    2     2     1     2  13\n",
      "15      2    2    1     1     1     2  46\n",
      "16      2    2    2     2     2     1  66\n",
      "No      -  [1]  [8]  [11]  [13]  [15]   -\n",
      "Compo  bc    a    d   abd   acd  abcd   -\n"
     ]
    }
   ],
   "source": [
    "# Obtener los datos (como lista)\n",
    "sheet = client.open_by_key(SPREADSHEET_ID).worksheet(\"Sheet14\") # 最初のシートを取得\n",
    "\n",
    "# データを取得\n",
    "list_of_lists = sheet.get_all_values()\n",
    "\n",
    "df = pd.DataFrame.from_records(list_of_lists)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(index=0)\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "df = df.apply(pd.to_numeric)\n",
    "# Definir los nombres de los factores\n",
    "factors = df.columns.tolist()\n",
    "\n",
    "df['y'] = [29,17,22,10,29,35,26,28,13,35,46,60,21,13,46,66]\n",
    "data = df.copy()\n",
    "\n",
    "data = data.T\n",
    "data['No'] = ['-','[1]','[8]','[11]','[13]','[15]','-']\n",
    "data['Compo'] = ['bc', 'a','d', 'abd', 'acd', 'abcd','-']\n",
    "data = data.T\n",
    "\n",
    "data.to_excel('Data_1/data14.xlsx')\n",
    "\n",
    "print('Tabla 7.14 Asignacíon y datos')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 7.19 Tabla de análisis de varianza (ANOVA):\n",
      "          sum_sq   df          F    PR(>F)\n",
      "A          786.0  2.0   6.550000  0.080435\n",
      "B          676.0  1.0  11.266667  0.043844\n",
      "E           64.0  1.0   1.066667  0.377662\n",
      "D          196.0  1.0   3.266667  0.168429\n",
      "F           36.0  1.0   0.600000  0.495025\n",
      "G          100.0  1.0   1.666667  0.287190\n",
      "A:B       1728.0  2.0  14.400000  0.028976\n",
      "A:E         34.0  2.0   0.283333  0.771415\n",
      "B:E        256.0  1.0   4.266667  0.130793\n",
      "Residual   180.0  3.0        NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Tabla orgogonal L16 (A: 3 niveles, los demás: 2 niveles)\n",
    "\n",
    "# Convertir los factores al tipo categórico\n",
    "for factor in factors:\n",
    "    df[factor] = df[factor].astype('category')\n",
    "\n",
    "model = ols('y ~ A + B + E + D + F + G + A:B + A:E + B:E', data=df).fit()\n",
    "\n",
    "# Crear la tabla de análisis de varianza (ANOVA)\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Tabla 7.19 Tabla de análisis de varianza (ANOVA):\")\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 7.20 Tabla de análisis de varianza (después de pooling):\n",
      "          sum_sq   df      F    PR(>F)  mean_sq\n",
      "A          786.0  2.0   7.86  0.016234    393.0\n",
      "B          676.0  1.0  13.52  0.007891    676.0\n",
      "E           64.0  1.0   1.28  0.295165     64.0\n",
      "D          196.0  1.0   3.92  0.088195    196.0\n",
      "A:B       1728.0  2.0  17.28  0.001961    864.0\n",
      "B:E        256.0  1.0   5.12  0.058096    256.0\n",
      "Residual   350.0  7.0   1.00  0.500000     50.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "# Obtener la tabla de análisis de varianza\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table = pool(anova_table,['F','G', 'A:E'], 'Residual')\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Tabla 7.20 Tabla de análisis de varianza (después de pooling):\")\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-04 Método de Bloques Aleatorios y Experimento de Diseño en Árbol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Método de Bloques Aleatorios\n",
    "\n",
    "Se introduce un factor de bloque, que es un factor variable, en algunos de los factores seleccionados, y dentro de cada bloque se experimentan todos los niveles de los factores controlados (factores de parámetros), repitiendo esto en varios bloques.\n",
    "\n",
    "El factor de bloque es un factor no reproducible, como el día, el lote de materia prima o el suelo, y no tiene sentido buscar niveles óptimos. En el método de bloques aleatorios, se puede probar el efecto del factor de bloque y, además, estimar la variabilidad entre bloques. Es importante notar que el efecto del factor de bloque es una variabilidad aleatoria, a diferencia del efecto de los factores controlados, que es constante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4\n",
    "\n",
    "母数因子（４水準）を取り上げて実験を行うことになった。周囲の温度や湿度などの影響が考えられるため、実験日をブロック因子としてランダムに選んだ３日間に実験を行った。すなわち、１日にA1～A4の水準の実験をランダムな順序で行い、これを３日間にわたり反復し計１２回実施した。以下の設問に答えよ。\n",
    "1. データの構造式を示せ。\n",
    "2. 各平方和と自由度を計算して、表7.21の分散分析表を得た（平方和と自由度は、繰り返しのない二元配置実験の場合と同様に求めることが出来る）ブロック間変動 $ \\sigma_{R}^2 $を推定せよ。\n",
    "\n",
    "Se ha decidido realizar un experimento con un factor controlado (de 4 niveles). Debido a la posible influencia de factores como la temperatura y la humedad del entorno, se eligieron aleatoriamente tres días para llevar a cabo el experimento, considerando el día como un factor de bloque. Es decir, en cada día se realizó el experimento con los niveles A1 a A4 en un orden aleatorio, repitiendo este proceso durante tres días, para un total de 12 repeticiones. Responda las siguientes preguntas.\n",
    "1. Muestre la fórmula estructural de los datos.\n",
    "2. Calcule las sumas de cuadrados y los grados de libertad, y obtenga la tabla de análisis de varianza de la tabla 7.21 (las sumas de cuadrados y los grados de libertad se pueden calcular de la misma manera que en un experimento de diseño factorial sin repeticiones) y estime la variabilidad entre bloques $ \\sigma_{R}^2 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 7.21 Tabla de análisis de varianza\n",
      "0           S  DF     V    F0  E(V)\n",
      "Factor                             \n",
      "A         140   3  46.7  38.9  V(A)\n",
      "R          23   2  11.5  9.58  V(R)\n",
      "E(Error)    7   6  12.0   NaN  V(E)\n",
      "Total     170  11   NaN   NaN      \n"
     ]
    }
   ],
   "source": [
    "# Obtener los datos (como lista)\n",
    "sheet = client.open_by_key(SPREADSHEET_ID).worksheet(\"Sheet16\") # 最初のシートを取得\n",
    "\n",
    "# データを取得\n",
    "list_of_lists = sheet.get_all_values()\n",
    "\n",
    "df = pd.DataFrame.from_records(list_of_lists)\n",
    "df.columns = df.iloc[0]\n",
    "df = df[1:]\n",
    "df = df.set_index(df.columns[0])\n",
    "\n",
    "df.iloc[:,:-1] = df.iloc[:,:-1].apply(pd.to_numeric)\n",
    "\n",
    "data = df.copy()\n",
    "\n",
    "print('Tabla 7.21 Tabla de análisis de varianza')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Estructura de los datos\n",
    "\n",
    "$ x_{ij} = \\mu + a_i + r_j + \\epsilon_{ij} $\n",
    "\n",
    "$ \\sum_i^4 a_i = 0, \\qquad r_j\\sim N(0, \\sigma_{R}^2), \\qquad \\epsilon_{ij} \\sim N(0, \\sigma^2) $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Estimación de la varianza del factor bloque\n",
    "\n",
    "1. Se realizarán experimentos con 4 niveles (A1 a A4)\n",
    "2. Se repetirá durante 3 días, realizando un total de 12 experimentos\n",
    "\n",
    "$ Var(A) = \\sigma^2 + 3 \\sigma_A^2 $\n",
    "\n",
    "$ Var(R) = \\sigma^2 + 4 \\sigma_R^2 $\n",
    "\n",
    "$ Var(E) = \\sigma^2 $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variabilidad enttre bloques (V_R - V_E)/4: 2.58\n"
     ]
    }
   ],
   "source": [
    "# Datos proporcionados\n",
    "S_A = df.iloc[0,0]\n",
    "DF_A = df.iloc[0,1]\n",
    "S_R = df.iloc[1,0]\n",
    "DF_R = df.iloc[1,1]\n",
    "S_E = df.iloc[2,0]\n",
    "DF_E = df.iloc[2,1]\n",
    "\n",
    "# Cálculo de la varianza (V)\n",
    "V_A = S_A / DF_A\n",
    "V_R = S_R / DF_R\n",
    "V_E = S_E / DF_E\n",
    "\n",
    "# Cálculo del valor F\n",
    "F_0_A = V_A / V_E\n",
    "F_0_R = V_R / V_E\n",
    "\n",
    "# Estimación de la variabilidad entre bloques\n",
    "k = 4 # 4 niveles (A1 a A4)\n",
    "sigma_R_squared = (V_R - V_E)/k\n",
    "\n",
    "print(f\"Variabilidad enttre bloques (V_R - V_E)/4: {sigma_R_squared:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Experimento de Diseño en Árbo\n",
    "\n",
    "El experimento ramificado es un diseño experimental cuyo objetivo es la estimación de los componentes de la varianza.\n",
    "\n",
    "Por ejemplo, si se toman dos muestras de varios lotes y la muestra se mide dos veces, es posible determinar el error entre lotes, el error entre muestras y el error de medición."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5\n",
    "\n",
    "Q社では、１バッチを１ロットとする生産方式で、工業用薬品を製造している。この製品は不純物Cの含有量が重要特性であり、今回、そのばらつき状況を把握するため、枝分かれ実験を行った。実験は、ランダムに選んだ $ l = 3 $ ロット $ (L_1 \\sim L_3) $ から、それぞれランダムに $ m=2 $ サンプル $ (S_1 \\sim S_2) $ 採取し、それぞれのサンプルを $ n = 2 $ 回ずつ不純物 $ C $ の含有率を測定 $ (M_1, M_2)$した。得られたデータから、ロット間変動、サンプリング誤差、測定誤差を推定する。以下の設問に答えよ。\n",
    "1. データの構造式を示せ\n",
    "2. 得られた表７．２２　分散分析表から、各分散成分を推定せよ\n",
    "\n",
    "En la empresa Q, se fabrica un producto químico industrial mediante un sistema de producción en el que un lote corresponde a un solo batch. Este producto tiene como característica importante el contenido de la impureza C, y en esta ocasión, se realizó un experimento ramificado para comprender la variabilidad de dicha impureza.\n",
    "\n",
    "El experimento se llevó a cabo seleccionando aleatoriamente $ l=3 $ lotes $(L_1 \\sim L_3) $, de los cuales se tomaron aleatoriamente $ m=2 $ muestras $ (S_1 \\sim S_2) $ de cada lote. Luego, el contenido de la impureza C en cada muestra se midió $ n=2 $ veces $ (M_1, M_2) $.\n",
    "\n",
    "A partir de los datos obtenidos, se estimaron la variabilidad entre lotes, el error de muestreo y el error de medición. Responda las siguientes preguntas.\n",
    "\n",
    "1. Muestre la fórmula estructural de los datos.\n",
    "2. A partir de la tabla de análisis de varianza (Tabla 7.22) obtenida, estime cada componente de varianza.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 7.22 Tabla de análisis de varianza\n",
      "0            S  DF     V    F0 E(V)\n",
      "Factor                             \n",
      "L         82.7   2  41.4   9.7   VL\n",
      "S         12.8   3  4.27  4.64   VS\n",
      "M          5.5   6  0.92   NaN   VM\n",
      "Total    101.0  11   NaN   NaN     \n"
     ]
    }
   ],
   "source": [
    "# Obtener los datos (como lista)\n",
    "sheet = client.open_by_key(SPREADSHEET_ID).worksheet(\"Sheet17\") # 最初のシートを取得\n",
    "\n",
    "# データを取得\n",
    "list_of_lists = sheet.get_all_values()\n",
    "\n",
    "df = pd.DataFrame.from_records(list_of_lists)\n",
    "df.columns = df.iloc[0]\n",
    "df = df[1:]\n",
    "df = df.set_index(df.columns[0])\n",
    "\n",
    "df.iloc[:,:-1] = df.iloc[:,:-1].apply(pd.to_numeric)\n",
    "\n",
    "data = df.copy()\n",
    "\n",
    "print('Tabla 7.22 Tabla de análisis de varianza')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Estructura de los datos\n",
    "\n",
    "$ x_{ijk} = \\mu + \\alpha_i + \\beta_{ij} + \\epsilon_{ijk} $\n",
    "\n",
    "$ \\alpha_{i}: $ Variación entre lotes\n",
    "\n",
    "$ \\beta_{ij}: $ Error de muestreo\n",
    "\n",
    "$ \\epsilon_{ijk} :$ Error de medición\n",
    "\n",
    "$ V(\\alpha_{i}) = \\sigma_L^2 $\n",
    "\n",
    "$ V(\\beta_{ij}) = \\sigma_S^2 $\n",
    "\n",
    "$ V(\\epsilon_{ijk}) = \\sigma_M^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-05 Método de división\n",
    "\n",
    "### 1. Método de división\n",
    "\n",
    "Los experimentos del diseño factorial de dos factores y los diseños factoriales de múltiples dimensiones se basan en la premisa de realizarse en un orden aleatorio. Sin embargo, en la  práctica, no siempre es fácil llevar a cabo los experimentos en un orden completamente aleatorio.\n",
    "\n",
    "##### (1) Puntos clave del método de división\n",
    "\n",
    "1. El factor cuyo nivel es difícil de cambiar se considera el primer factor, mientras que el factor cuyo nivele es relativamente fácil de cambiar se toma como el segundo factor. Además, también se puede considerar un tercer, un cuarto, y así sucesivamente.\n",
    "2. El método de división en dos etapas se refiere a la consideración de hasta tres factores, mientras que el método de división en tres etapas se aplica cuando se consideran hasta cuatro factores.\n",
    "3. Al establecer los niveles del primer factor, se genera un error primario, el cual se considera que persiste como un error común incluso cuando se cambian los niveles del segundo factor.\n",
    "4. Al establecer los niveles del segundo factor, se genera un error secundario. De esta manera, en el método de división, cada división introduce un nuevo error, dando lugar a la aparición de múltiples errores.\n",
    "5. La unidad en la que el error primario es común para una combinación de niveles se denomina unidad primaria, y la unidad en la que el error secundario es común se llama unidad secundaria. Lo mismo se aplica a los niveles tercero y siguientes.\n",
    "6. Debido a la reducción en los grados de libertad del error primario, el poder de detección del efecto del primer factor disminuye."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Método de división utilizando una tabla ortogonal de 2 niveles\n",
    "\n",
    "En los experimentos con diseños de tablas ortogonales, también es posible aplicar el método de división. En el método de división utilizando tablas ortogonales, se utilizan los grupos indicados en la tabla ortogonal\n",
    "\n",
    "#### (1) Puntos clave del método de división utilizando una tabla ortogonal de dos niveles\n",
    "\n",
    "1. El primer factor se asigna a varios grupos consecutivos dentro de un grupo. Las columnas que pertenecen a estos grupos se denominan unidades primarias.\n",
    "2. El segundo factor se asigna a varios grupos consecutivos que siguen al grupo de unidades primarias. Lo mismo se aplica si hay un tercer factor. Las columnas que pertenecen a estos grupos se denominan columnas de unidades secundarias, unidades terciarias, y así sucesivamente.\n",
    "3. Las columnas en las que aparece la interacción tienen las siguientes reglas.\n",
    "* La interacción entre dos columnas asignadas a diferentes grupos aparece en el grupo de mayor grado.\n",
    "* La interacción entre dos columnas asignadas al mismo grupo aparece en el grupo de menor dimensión.\n",
    "4. Las columnas vacías del grupo al que se asigna el primer factor se consideran como error primario, y las columnas vacías del grupo al que se asigna el segundo factor se consideran como error secundario. Lo mismo se aplica para los factores de tercer nivel en adelante.\n",
    "5. El cálculo de la suma de los cuadrados y los grados de libertad para factor se realiza de la misma manera que en la sección 7.2.\n",
    "6. La elaboración de la tabla de análisis de varianza y el procedimiento de prueba son los mismos que en el método de división.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6\n",
    "\n",
    "Q社では金属材料の強度を上げる検討をしている。強度に影響を及ぼすと考えられるA、B、C、D、Fの5つの母数因子（いずれも２水準）を取り上げて実験を行うことになった。交互作用としては、ＡｘＣ、ＢｘＤ、ＢｘＦ、ＣｘＦが考えらえる。実験はＬ１８直交配列表を用いて以下の方法で実施した。\n",
    "1. 一日に８回しか実験が出来ないので、反復Ｒをいれて、２日間にわたって８回ずつ実験を反復する。反復Ｒを割り付けた第[1]列のブロックに着目して、「Ｎｏ１～Ｎｏ８」のブロックの実験と「Ｎｏ９～Ｎｏ１６」のどちらを先に行うのかをランダムに定める。その結果「Ｎｏ９～Ｎｏ１６」→「Ｎｏ１～Ｎｏ８」となった。\n",
    "2. 一次因子ＡとＢの４通りの水準組み合わせ「果、A1B2→A2B2→A2B1→A1B1とした。\n",
    "3. 「Ｎｏ９～Ｎｏ１６］においてA1B2水準で行う実験、すなわち、Ｎｏ１１とＮｏ１２のどちらを先に実験するかをランダムに定める。その結果、Ｎｏ１１→Ｎｏ１２とした。\n",
    "4. A1B2水準で作成された半製品について、Ｎｏ１１のＣ、Ｄ、Ｆの水準で複合材を作成し、強度を測定する。\n",
    "5. 前日の2.で定めた順序に従って、同様に実験と測定を行う。\n",
    "6. もう一度反復し、Ｎｏ１～Ｎｏ８の実験をおこなう。順序は、再びランダムな順序にする。\n",
    "\n",
    "割り付け、実験順序、得られたデータを表７．２３に示す。データは、値が大きい方が望ましい。\n",
    "以下の設問に答えよ。\n",
    "\n",
    "2. データの構造式を示せ。\n",
    "3. 分散分析表を作成せよ。\n",
    "4. プーリング後の分散分析表を作成せよ。\n",
    "5. 分散分析後の構造式を示せ。\n",
    "6. 最適条件における母平均の点推定値を信頼率９５％区間で推定せよ。\n",
    "\n",
    "\n",
    "La empresa Q está investigando cómo mejora la resistencia de los materiales metálicos. Se han identificado cinco factores principales que pueden influir en la resistencia: A, B, C, D y F. El experimento se llevó a cabo utilizando una matriz ortogonal L18 según el siguiete método.\n",
    "\n",
    "1. Como solo se pueden realizar 8 experimentos por día, se introduce la repetición R y se repiten 8 experimentos durante dos días. Enfocándose en el bloque de la primera columna al que se asigna la repetición R, se determina aleatoriamente si se debe realizar primero el experimento del bloque No1 a No8 o el del bloque No9 a No16. El resultado fue No9 a No16 → No1 a No8.\n",
    "2. Se establecieron las cuatro combinaciones de niveles de los factores principales A y B como sigue: A1B2→A2B2→A2B1→A1B1.\n",
    "3. En el bloque de No9 a No16, se determina aleatoriamente cuál de los experimentos A1B2 se realizará primero, es decir, si se realizará primero el experimento No11 o el No12. El resultado fue No11→No12.\n",
    "4. Para los semi-productos creados en el nivel A1B2, se fabricarán materiales compuestos en los niveles C, D y F del No11, se medirá su resistencia.\n",
    "5. Siguiendo el orden determinado en el punto 2 del día anterior, se realizarán los experimentos y mediciones de la misma manera.\n",
    "6. Se repetirá nuevamente y se realizarán los experimentos de No1 a No8. El orden será nuevamente aleatorio.\n",
    "\n",
    "La asignación, el orden de los experimentos y los datos obtenidos se muestran en la tabla 7.23. Se desea que los valores sean lo más grandes posible. Responde a los siguientes.\n",
    "\n",
    "2. Muestre la fórmula de la estructura de los datos.\n",
    "3. Cree la tabla de análisis de varianza.\n",
    "4. Cree la tabla de análisis de varianza después de la agrupación.\n",
    "5. Muestra la fórmula de la estructura después del análisis de varianza.\n",
    "6. Estime el valor puntual de la media poblacional bajo las condiciones óptimas en un intervalo de confianza del 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Estructura de los datos\n",
    "\n",
    "$ x = \\mu + r + a + b + (cf) + \\epsilon(1) c + d + f + (ac) + (bd) + (bf) + \\epsilon(2) $\n",
    "\n",
    "$ \\sum a = \\sum b = \\sum c = \\sum d = \\sum f = 0 $\n",
    "\n",
    "$ \\sum (ac) = \\sum (bd) = \\sum (bf) = \\sum (cf) = 0 $\n",
    "\n",
    "$ r \\sim N(0, \\sigma_R^2 ), \\qquad \\epsilon(1) \\sim N(0, \\sigma_{(1)}^2), \\qquad \\epsilon(2) \\sim N(0, \\sigma_{(2)}^2 ) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los datos (como lista)\n",
    "sheet = client.open_by_key(SPREADSHEET_ID).worksheet(\"Sheet12\") # 最初のシートを取得\n",
    "\n",
    "# データを取得\n",
    "list_of_lists = sheet.get_all_values()\n",
    "\n",
    "df = pd.DataFrame.from_records(list_of_lists)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(index=0)\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "df = df.apply(pd.to_numeric)\n",
    "\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.T\n",
    "data['No'] = ['[1]','[2]','[3]','[4]','[5]','[7]','[8]','[12]','[13]','[14]','[15]','-']\n",
    "data['Compo'] = ['a','b','ab','c','ac','abc','d','cd','acd','bcd','abcd','-']\n",
    "data['grupo'] = [1,2,2,3,3,3,4,4,4,4,4,\"-\"]\n",
    "data = data.T\n",
    "\n",
    "data['Orden'] = [11,12,16,15,14,13,9,10,8,7,1,2,5,6,4,3,'-','-','-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 7.23 Tabla de análisis de varianza\n",
      "0        R    A   h3    B   h5   e1    C   h12     D   h14     F   x Orden\n",
      "1        1    1    1    1    1    1    1     1     1     1     1  25    11\n",
      "2        1    1    1    1    1    1    2     2     2     2     2  14    12\n",
      "3        1    1    1    2    2    2    1     2     2     2     2  32    16\n",
      "4        1    1    1    2    2    2    2     1     1     1     1  29    15\n",
      "5        1    2    2    1    1    2    1     1     1     1     2  20    14\n",
      "6        1    2    2    1    1    2    2     2     2     1     1  22    13\n",
      "7        1    2    2    2    2    1    1     2     2     1     1  17     9\n",
      "8        1    2    2    2    2    1    2     1     1     2     2  21    10\n",
      "9        2    1    2    1    2    1    1     1     2     1     2  27     8\n",
      "10       2    1    2    1    2    1    2     2     1     2     1  28     7\n",
      "11       2    1    2    2    1    2    1     2     1     2     1  36     1\n",
      "12       2    1    2    2    1    2    2     1     2     1     2  22     2\n",
      "13       2    2    1    1    2    2    1     1     2     2     1  21     5\n",
      "14       2    2    1    1    2    2    2     2     1     1     2  17     6\n",
      "15       2    2    1    2    1    1    1     2     1     1     2  23     4\n",
      "16       2    2    1    2    1    1    2     1     2     2     1  22     3\n",
      "No     [1]  [2]  [3]  [4]  [5]  [7]  [8]  [12]  [13]  [14]  [15]   -     -\n",
      "Compo    a    b   ab    c   ac  abc    d    cd   acd   bcd  abcd   -     -\n",
      "grupo    1    2    2    3    3    3    4     4     4     4     4   -     -\n"
     ]
    }
   ],
   "source": [
    "data.to_excel('Data_1/data.xlsx')\n",
    "\n",
    "print('Tabla 7.23 Tabla de análisis de varianza')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Tabla de análisis de varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from scipy import stats\n",
    "\n",
    "formula = 'x ~ R + A + h3 + B + h5 + C:F + e1  + C  + D + F + A:C + B:D + B:F'\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = anova_lm(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 7.26 \n",
      "          sum_sq   df          F    PR(>F)  mean_sq\n",
      "R          16.00  1.0   1.185185  0.355940   16.000\n",
      "A         156.25  1.0  11.574074  0.042397  156.250\n",
      "B          49.00  1.0   3.629630  0.152853   49.000\n",
      "C:F        56.25  1.0   4.166667  0.133887   56.250\n",
      "e1         40.50  3.0   2.918919  0.265498   13.500\n",
      "C          42.25  1.0   9.135135  0.094247   42.250\n",
      "D          30.25  1.0   6.540541  0.124887   30.250\n",
      "F          36.00  1.0   7.783784  0.108047   36.000\n",
      "A:C        49.00  1.0  10.594595  0.082830   49.000\n",
      "B:D         6.25  1.0   1.351351  0.364999    6.250\n",
      "B:F         9.00  1.0   1.945946  0.297753    9.000\n",
      "Residual    9.25  2.0   1.000000  0.500000    4.625\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table = pool(anova_table, ['h3', 'h5'], 'e1')\n",
    "\n",
    "adusts = ['R','A','B','C:F' ]\n",
    "for adust in adusts:\n",
    "  anova_table.loc[adust,'F'] = anova_table.loc[adust,'mean_sq']/anova_table.loc['e1','mean_sq']\n",
    "  anova_table.loc[adust,'PR(>F)'] = f.sf(anova_table.loc[adust,'F'], anova_table.loc[adust,'df'], anova_table.loc['e1','df'])\n",
    "\n",
    "print(\"Tabla 7.26 \")\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Tabla de análisis de varianza después de la agrupación\n",
    "\n",
    "Pooling: El factor de primer orden se prueba con error de primer orden, y el factor de segundo orden se prueba con el error de segundo orden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 7.27 Tabla de análisis de varianza después del pooling:\n",
      "          sum_sq   df          F    PR(>F)  mean_sq\n",
      "A         156.25  1.0  11.061947  0.029216  156.250\n",
      "B          49.00  1.0   3.469027  0.136001   49.000\n",
      "C:F        56.25  1.0   3.982301  0.116705   56.250\n",
      "e1         56.50  4.0   2.306122  0.219118   14.125\n",
      "C          42.25  1.0   6.897959  0.058406   42.250\n",
      "D          30.25  1.0   4.938776  0.090377   30.250\n",
      "F          36.00  1.0   5.877551  0.072420   36.000\n",
      "A:C        49.00  1.0   8.000000  0.047421   49.000\n",
      "Residual   24.50  4.0   1.000000  0.500000    6.125\n"
     ]
    }
   ],
   "source": [
    "# Obtener la tabla de análisis de varizanza (factor de primer orden)\n",
    "anova_table = anova_table.drop(columns=anova_table.columns[-1])\n",
    "anova_table = pool(anova_table, ['R'], 'e1')\n",
    "\n",
    "# Obtener la tabla de análisis de varianza (factor de segundo orden)\n",
    "anova_table = anova_table.drop(columns=anova_table.columns[-1])\n",
    "anova_table = pool(anova_table,['B:D','B:F'], 'Residual')\n",
    "\n",
    "# Recalcular F0 y el valor p del factor de primer orden\n",
    "adusts = ['A','B','C:F' ]\n",
    "for adust in adusts:\n",
    "  anova_table.loc[adust,'F'] = anova_table.loc[adust,'mean_sq']/anova_table.loc['e1','mean_sq']\n",
    "  anova_table.loc[adust,'PR(>F)'] = f.sf(anova_table.loc[adust,'F'], anova_table.loc[adust,'df'], anova_table.loc['e1','df'])\n",
    "\n",
    "print(\"Tabla 7.27 Tabla de análisis de varianza después del pooling:\")\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Estructura de los datos\n",
    "\n",
    "$ x = \\mu + a + b + (cf) + \\epsilon(1) + c + d + f + (ac) + \\epsilon(2) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Estimación de la media poblacional en la condición óptima\n",
    "\n",
    "6-1 Estimación puntual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nivel de la condición óptima: {'A': 1, 'C': 1, 'F': 2, 'B': 2, 'D': 1}\n",
      "Valor estimado de la media poblacional en la condición óptima: 33.5\n"
     ]
    }
   ],
   "source": [
    "means = 0\n",
    "optimal_levels = {}  # Diccionario para almacenar la condición óptima\n",
    "\n",
    "for factor in [['A', 'C'], ['C', 'F'], 'B', 'D']:\n",
    "    group_means = df.groupby(factor)['x'].mean()\n",
    "    best_factor_level = group_means.idxmax()  # Obtener el nivel con la media máxima\n",
    "    means += group_means.max()\n",
    "\n",
    "    # Guardar la condición óptima en el diccionario\n",
    "    if isinstance(best_factor_level, tuple):  # En caso de múltiples factores\n",
    "        for i, f in enumerate(factor):\n",
    "            optimal_levels[f] = best_factor_level[i]\n",
    "    else:  # En caso de un solo factor\n",
    "        optimal_levels[factor] = best_factor_level\n",
    "\n",
    "mean_x = means - df.groupby(['C'])['x'].mean().max() - 2 * df['x'].mean()\n",
    "\n",
    "print(\"Nivel de la condición óptima:\", optimal_levels)\n",
    "print(f\"Valor estimado de la media poblacional en la condición óptima: {mean_x}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-2 Estimación por intervalo:\n",
    "\n",
    "Para la estimación por intervalo de la media poblacional en el método de división, se aplica fórmula de Taguchi en el caso de ignorar las repeticiones para determinar el número efectivo de repeticiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.25 14.12499999999999 6.12499999999999 4.0 4.0\n"
     ]
    }
   ],
   "source": [
    "# Estimación por intervalo\n",
    "\n",
    "N = len(df)\n",
    "\n",
    "s = 1\n",
    "for i in ['A','B','C:F']:\n",
    "  s += anova_table.loc[i,'df']\n",
    "ne1 = s/N\n",
    "\n",
    "s = 0\n",
    "for i in ['A','D','F', 'A:C']:\n",
    "  s += anova_table.loc[i,'df']\n",
    "ne2 = s/N\n",
    "\n",
    "Ve1 = anova_table.loc['e1','mean_sq']\n",
    "Ve2 = anova_table.loc['Residual','mean_sq']\n",
    "\n",
    "dfe1 = anova_table.loc['e1','df']\n",
    "dfe2 = anova_table.loc['Residual','df']\n",
    "\n",
    "print (ne1, ne2, Ve1, Ve2, dfe1, dfe2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los grados de libertad $ \\phi $ se determinan mediante el método de Satterthwaite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grados de libertad: 6.9\n"
     ]
    }
   ],
   "source": [
    "# Satterthwaite\n",
    "\n",
    "def satterthwaite_df(ne1, ne2, Ve1, Ve2, dfe1, dfe2):\n",
    "    df = (ne1*Ve1 + ne2*Ve2)**2 /(((ne1*Ve1)**2)/dfe1 + ((ne2*Ve2)**2)/dfe2)\n",
    "    return df\n",
    "\n",
    "df = satterthwaite_df(ne1, ne2, Ve1, Ve2, dfe1, dfe2)\n",
    "print(f\"Grados de libertad: {df:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grados de libertad 6.9, p = 0.05 Valor t: 2.373\n",
      "Intervalo de confianza (95%): (28.2, 38.8)\n"
     ]
    }
   ],
   "source": [
    "# Intervalo de confianza\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "def interpolated_t_value(df, p=0.05):\n",
    "    df_low = int(df)  # Grados de libertad enteros pequeños\n",
    "    df_high = df_low + 1  # Grados de libertad enteros grandes\n",
    "    w = df - df_low  # Peso de juste\n",
    "\n",
    "    t_low = stats.t.ppf(1 - p/2, df_low)\n",
    "    t_high = stats.t.ppf(1 - p/2, df_high)\n",
    "\n",
    "    # Método de interpolación lineal\n",
    "    t_interpolated = (1 - w) * t_low + w * t_high\n",
    "\n",
    "    return t_interpolated\n",
    "\n",
    "df = 6.9\n",
    "p = 0.05\n",
    "t_value = interpolated_t_value(df)\n",
    "print(f\"Grados de libertad {df}, p = {p} Valor t: {t_value:.3f}\")\n",
    "\n",
    "S = (ne1*Ve1 + ne2*Ve2)**0.5\n",
    "\n",
    "UL = mean_x + t_value*S\n",
    "LL = mean_x - t_value*S\n",
    "print(f\"Intervalo de confianza (95%): ({LL:.1f}, {UL:.1f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Método de división utilizando una tabla ortogonal de 3 niveles\n",
    "\n",
    "La implementación y el análisis del método de división utilizando una tabla ortogonal de tres niveles pueden realizarse de la misma manera que en el caso de dos niveles. Sin embargo, en el caso de tres niveles, la interacción aparece distribuida en dos columnas, por lo que es necesario tener en cuenta que pueden dividirse entre el factor de primer nivel y el de segundo nivel. Las columnas de la tabla ortogonal de tres niveles también están agrupadas, y en el caso de la tabla ortogonal L27, se dividen en tres grupos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-06 Método de superficie de respuesta y polinomios ortogonales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Método de superficie de respuesta\n",
    "\n",
    "En los métodos de diseño experimental descritos hasta ahora, aunque los factores puedan ser valores continuos como la temperatura o la cantidad añadida, durante la realización del experimento se establece un nivel y se trata como factores discretos de valores numéricos.\n",
    "\n",
    "Sin embargo, dado que los factores reales toman valores continuos, no siempre se garantiza que la combinación de niveles óptimos sea la condición óptima.\n",
    "\n",
    "El método de superficie de respuesta establece la relación entre la variable de respuesta $ y $, como variable explicativa continua, la variable $ x $ como una superficie, es un método para determinar el nivel óptimo como variable continua."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Polinomios ortogonales\n",
    "\n",
    "En experimentos de diseño unifactorial, cuando el factor considerado es un factor cuantitativo, las distancias entre los niveles son iguales y el número de repeticiones de cada nivel es el mismo, se puede descomponer y analizar la variabilidad de ese factor utilizando polinomios ortogonales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook QCKentei1-7.ipynb to html\n",
      "[NbConvertApp] Writing 769867 bytes to QCKentei1-7.html\n"
     ]
    }
   ],
   "source": [
    "notebook_name = 'QCKentei1-7.ipynb'\n",
    "notebook_name_html = notebook_name.replace(\".ipynb\",\".html\")\n",
    "\n",
    "!jupyter nbconvert --to html {notebook_name}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
